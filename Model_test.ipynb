{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RepeatedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSolarModules = pd.read_json('InfraredSolarModules/module_metadata.json').transpose().sort_index()\n",
    "Classes = DataSolarModules['anomaly_class'].unique()\n",
    "class_to_number = dict(enumerate(Classes.flatten(), 0))\n",
    "class_to_number = {v: k for k, v in class_to_number.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_class(value):\n",
    "    class_to_number\n",
    "    return class_to_number.get(value, 'Unknown')\n",
    "\n",
    "DataSolarModules['class_code'] = DataSolarModules['anomaly_class'].apply(map_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_dataframe(dataframe):\n",
    "    images = []\n",
    "    for image_path in dataframe['image_filepath']:\n",
    "        img = cv2.imread(\"InfraredSolarModules/\"+image_path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = img.reshape(40, 24).astype(\"float32\") / 255\n",
    "        images.append(img)\n",
    "    images=np.array(images) \n",
    "    return images\n",
    "\n",
    "def read_labels_dataframe(dataframe):\n",
    "    labels = []\n",
    "    for label in dataframe['class_code']:\n",
    "        labels.append(label)\n",
    "    labels=np.array(labels) \n",
    "    labels.astype(\"int32\")   \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = read_images_dataframe(DataSolarModules)\n",
    "labels = read_labels_dataframe(DataSolarModules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(40, 24, 1))\n",
    "\n",
    "\n",
    "x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(2048, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.4, noise_shape=None, seed=None)(x)\n",
    "x = layers.Dense(1024, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.4, noise_shape=None, seed=None)(x)\n",
    "x = layers.Dense(512, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.4, noise_shape=None, seed=None)(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.4, noise_shape=None, seed=None)(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "\n",
    "outputs = layers.Dense(12, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_epochs = 25\n",
    "\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=6, n_repeats=3, random_state=21312312)\n",
    "datos = list(range(0,len(DataSolarModules)))\n",
    "\n",
    "data_train, data_test = train_test_split(datos, test_size=0.2)\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer,                                    \n",
    "              loss=\"sparse_categorical_crossentropy\",                 \n",
    "              metrics=[\"accuracy\"])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_no = 1\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "all_train_losses = []\n",
    "all_train_accuracies = []\n",
    "all_val_losses = []\n",
    "all_val_accuracies = []\n",
    "\n",
    "for train, val in rkf.split(data_train):\n",
    "\n",
    "    history_model = model.fit(images[train], labels[train],\n",
    "                              epochs=n_epochs,\n",
    "                              validation_data=(images[val], labels[val]),\n",
    "                              batch_size=batch_size)\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    fold_train_loss = np.mean(history_model.history['loss'])\n",
    "    fold_train_accuracy = np.mean(history_model.history['accuracy'])\n",
    "    fold_val_loss = np.mean(history_model.history['val_loss'])\n",
    "    fold_val_accuracy = np.mean(history_model.history['val_accuracy'])\n",
    "\n",
    "    all_train_losses.append(fold_train_loss)\n",
    "    all_train_accuracies.append(fold_train_accuracy)\n",
    "    all_val_losses.append(fold_val_loss)\n",
    "    all_val_accuracies.append(fold_val_accuracy)\n",
    "\n",
    "    # Generate generalization metrics for the last epoch\n",
    "    scores = model.evaluate(images[val], labels[val],verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1] * 100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(range(1, len(all_train_losses) + 1), all_train_losses, color='blue')\n",
    "plt.title('Average Training Loss')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(range(1, len(all_val_losses) + 1), all_val_losses, color='orange')\n",
    "plt.title('Average Validation Loss')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(range(1, len(all_train_accuracies) + 1), [acc * 100 for acc in all_train_accuracies], color='green')\n",
    "plt.title('Average Training Accuracy')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(range(1, len(all_val_accuracies) + 1), [acc * 100 for acc in all_val_accuracies], color='red')\n",
    "plt.title('Average Validation Accuracy')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = model.evaluate(images[data_test], labels[data_test])  \n",
    "print(\"Test loss:\", test_metrics[0])\n",
    "print(\"Test accuracy:\", test_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Confusion Matrix\n",
    "predictions = model.predict(images[data_test], steps=len(data_test), verbose=0)\n",
    "\n",
    "y_pred = np.argmax(predictions, axis=-1)\n",
    "\n",
    "cm = confusion_matrix(labels[data_test], y_pred)\n",
    "\n",
    "## Get Class Labels\n",
    "class_names = Classes\n",
    "\n",
    "# Plot confusion matrix in a beautiful manner\n",
    "fig = plt.figure(figsize=(16, 14))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True,robust=True, ax = ax, fmt = 'g'); #annot=True to annotate cells\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted', fontsize=20)\n",
    "ax.xaxis.set_label_position('bottom')\n",
    "plt.xticks(rotation=90)\n",
    "ax.xaxis.set_ticklabels(class_names, fontsize = 10)\n",
    "ax.xaxis.tick_bottom()\n",
    "\n",
    "ax.set_ylabel('True', fontsize=20)\n",
    "ax.yaxis.set_ticklabels(class_names, fontsize = 10)\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "plt.title('Refined Confusion Matrix', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_and_fn = cm.sum(1)\n",
    "tp_and_fp = cm.sum(0)\n",
    "tp = cm.diagonal()\n",
    "accuracy = cm.diagonal().sum()/cm.sum()\n",
    "precision = tp / tp_and_fp\n",
    "recall = tp / tp_and_fn\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "precision_avg=np.average(precision)\n",
    "recall_avg=np.average(recall)\n",
    "f1_avg=np.average(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary with the data\n",
    "data = {\n",
    "    'Metrics': ['Accuracy', 'Average Precision', 'Average Recall', 'Average F1 Score'],\n",
    "    'Values': [accuracy, precision_avg, recall_avg, f1_avg]\n",
    "}\n",
    "\n",
    "# Creating the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Displaying the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Class': class_names,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1\n",
    "}\n",
    "\n",
    "# Creating the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Displaying the DataFrame\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.Keras': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c6bf8e3c71d29b289656a0e522ae20919f8da47e1e0df367350538eb0f05593"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
